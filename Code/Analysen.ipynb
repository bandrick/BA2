{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xgboost\n",
    "import lightgbm as lgb\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(base_folder):\n",
    "    \"\"\"\n",
    "    Process a folder containing new_properties_2.csv and conformance_results.json\n",
    "    \"\"\"\n",
    "    print(base_folder)\n",
    "    if str(base_folder) == \"/home/jupyter-benjamin.andrick-3cf07/test/logs/inductive_logs\":\n",
    "        conf_path = os.path.join(base_folder, 'conformance_results copy.json')\n",
    "        props_path = os.path.join(base_folder, 'new_properties_2 copy.csv')\n",
    "    else:\n",
    "        conf_path = os.path.join(base_folder, 'conformance_results.json')\n",
    "        props_path = os.path.join(base_folder, 'new_properties_2.csv')\n",
    "    \n",
    "    if not (os.path.exists(props_path) and os.path.exists(conf_path)):\n",
    "        return None, None\n",
    "    props_df = pd.read_csv(props_path)\n",
    "    with open(conf_path, 'r') as f:\n",
    "        conf_data = json.load(f)\n",
    "        \n",
    "    return props_df, conf_data\n",
    "\n",
    "\n",
    "\n",
    "def flatten_conformance_data(json_data):\n",
    "    \"\"\"\n",
    "    Flatten the conformance JSON data into a DataFrame, excluding specific metrics\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    metrics_to_exclude = ['perc_fit_traces', 'average_trace_fitness', 'percentage_of_fitting_traces']\n",
    "    \n",
    "    for item in json_data:\n",
    "        for filename, data in item.items():\n",
    "            miners_data = data.get('conformance', data)\n",
    "            for miner, metrics in miners_data.items():\n",
    "                filtered_metrics = {k: v for k, v in metrics.items() if k not in metrics_to_exclude}\n",
    "                metrics_flat = {\"file\": filename, \"miner\": miner, **filtered_metrics}\n",
    "                flattened_data.append(metrics_flat)\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "def process_all_folders(root_path):\n",
    "    \"\"\"\n",
    "    Process all subfolders in the given root path\n",
    "    \"\"\"\n",
    "    merged_dfs = {}\n",
    "    \n",
    "    for folder_path in Path(root_path).iterdir():\n",
    "        if not folder_path.is_dir() or folder_path.name.startswith('.i'):\n",
    "            continue\n",
    "            \n",
    "        folder_name = folder_path.name\n",
    "        print(f\"Processing folder: {folder_name}\")\n",
    "        \n",
    "        props_df, conf_data = process_folder(folder_path)\n",
    "        \n",
    "        if props_df is None or conf_data is None:\n",
    "            print(f\"Skipping {folder_name} - missing required files\")\n",
    "            continue\n",
    "        conf_df = flatten_conformance_data(conf_data)\n",
    "        \n",
    "        merged_df = pd.merge(\n",
    "            conf_df,\n",
    "            props_df,\n",
    "            left_on='file',\n",
    "            right_on='File',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        merged_dfs[folder_name] = merged_df\n",
    "        \n",
    "    return merged_dfs\n",
    "\n",
    "root_path = '/home/jupyter-benjamin.andrick-3cf07/test/logs'\n",
    "merged_dfs = process_all_folders(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivations in Logfiles after Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_key_column(df):\n",
    "    \n",
    "    if 'filename' in df.columns:\n",
    "        df['Key'] = df['File'].str.extract(r'(.*?\\.xes)', expand=False)\n",
    "    else:\n",
    "        xes_columns = [col for col in df.columns if df[col].astype(str).str.contains('.xes').any()]\n",
    "        if xes_columns:\n",
    "            df['Key'] = df[xes_columns[0]].str.extract(r'(.*?\\.xes)', expand=False)\n",
    "        else:\n",
    "            print(\"Could not find a column containing filenames with .xes\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_properties(merged_dfs):\n",
    "    \"\"\"\n",
    "    Extract specified columns from merged dataframes, ensuring unique filenames.\n",
    "    \n",
    "    Args:\n",
    "        merged_dfs (dict): Dictionary of merged dataframes from process_all_folders()\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary of processed dataframes with unique properties per file\n",
    "    \"\"\"\n",
    "    columns_to_keep = [\n",
    "        \"Number of Events\", \"ATS\", \"Number of Traces\", \"Distinct Events\",\n",
    "        \"Distinct Traces\", \"Distinct Start Events\", \"Distinct End Events\",\n",
    "        \"Average Trace Length\", \"Max Trace Length\", \"Min Trace Length\",\n",
    "        \"Event Density\", \"Absolute Trace Coverage\", \"Relative Trace Coverage\",\n",
    "        \"Structure\", \"Level of Detail\", \"Traces with Self-loops\",\n",
    "        \"Total Self-loops\", \"Average Self-loop Size\", \"Event Diversity\",\n",
    "        \"Event Repeatability\", \"Transition Consistency\", \"Sequential Complexity\",\n",
    "        \"Rare Sequence Impact\", \"Event Class Dispersion\",\n",
    "        \"Event Co-occurrence Consistency\", \"Trace Variability\", \"File\"\n",
    "    ]\n",
    "    \n",
    "    processed_dfs = {}\n",
    "    \n",
    "    for df_name, df in merged_dfs.items():\n",
    "        try:\n",
    "            filename_col = 'File'\n",
    "            existing_columns = [col for col in columns_to_keep if col in df.columns]\n",
    "            #print(existing_columns)\n",
    "            processed_df = df[existing_columns].drop_duplicates(subset=[filename_col])\n",
    "            processed_df = add_key_column(processed_df)\n",
    "            \n",
    "            processed_dfs[df_name] = processed_df\n",
    "            \n",
    "            print(f\"Processed {df_name}: {len(processed_df)} unique files\")\n",
    "            print(f\"Processed {df_name}: {processed_df['File'].nunique()} unique files\")\n",
    "            \n",
    "            missing_columns = set(columns_to_keep) - set(existing_columns)\n",
    "            if missing_columns:\n",
    "                print(f\"Warning: Missing columns in {df_name}: {missing_columns}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {df_name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return processed_dfs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed combined_ind: 519 unique files\n",
      "Processed combined_ind: 519 unique files\n",
      "Processed standard: 548 unique files\n",
      "Processed standard: 548 unique files\n",
      "Processed case_size_filtered: 561 unique files\n",
      "Processed case_size_filtered: 561 unique files\n",
      "Processed inductive_logs: 561 unique files\n",
      "Processed inductive_logs: 561 unique files\n",
      "Processed variants_coverage_filtered: 563 unique files\n",
      "Processed variants_coverage_filtered: 563 unique files\n",
      "Processed variants_top_k_filtered: 543 unique files\n",
      "Processed variants_top_k_filtered: 543 unique files\n",
      "Processed combined_filters: 542 unique files\n",
      "Processed combined_filters: 542 unique files\n"
     ]
    }
   ],
   "source": [
    "props_with_keys_df = extract_unique_properties(merged_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_list = []\n",
    "\n",
    "for preproc_type, df in props_with_keys_df.items():\n",
    "    df_with_type = df.copy()\n",
    "    df_with_type['preprocessing_type'] = preproc_type\n",
    "    dfs_list.append(df_with_type)\n",
    "\n",
    "all_props_df = pd.concat(dfs_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_powerbi(df):\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.replace('[^A-Za-z0-9_]', '')\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    non_numeric_columns = ['File', 'Key', 'preprocessing_type']\n",
    "    \n",
    "    numeric_columns = [col for col in df.columns if col not in non_numeric_columns]\n",
    "    \n",
    "    for col in numeric_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "all_props_df_clean = prepare_for_powerbi(all_props_df)\n",
    "\n",
    "output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_file = os.path.join(output_dir, 'process_mining_analysis.csv')\n",
    "\n",
    "all_props_df_clean.to_csv(output_file, \n",
    "                         index=False, \n",
    "                         sep=';',\n",
    "                         decimal=',')\n",
    "print(f\"Successfully exported to CSV: {output_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation / Regression Analysis (multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models_old(X_train, X_test, y_train, y_test, target_name):\n",
    "\n",
    "    automl = AutoML()\n",
    "    \n",
    "    # Configure the AutoML settings\n",
    "    settings = {\n",
    "        \"time_budget\": 0.3,\n",
    "        \"task\": 'regression',\n",
    "        \"metric\": 'mse',\n",
    "        \"estimator_list\": ['rf'],\n",
    "        \"eval_method\": \"holdout\",\n",
    "        \"verbose\": 0,  # Reduced verbosity since we're saving to file\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        X_train = np.array(X_train).astype(np.float32)\n",
    "        X_test = np.array(X_test).astype(np.float32)\n",
    "        y_train = np.array(y_train).astype(np.float32)\n",
    "        y_test = np.array(y_test).astype(np.float32)\n",
    "        \n",
    "        data_info = {\n",
    "            \"shapes\": {\n",
    "                \"X_train\": X_train.shape,\n",
    "                \"y_train\": y_train.shape,\n",
    "                \"X_test\": X_test.shape,\n",
    "                \"y_test\": y_test.shape\n",
    "            },\n",
    "            \"statistics\": {\n",
    "                \"X_train_range\": [float(X_train.min()), float(X_train.max())],\n",
    "                \"y_train_range\": [float(y_train.min()), float(y_train.max())]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        automl.fit(X_train, y_train, **settings)\n",
    "        \n",
    "        y_pred = automl.predict(X_test)\n",
    "        \n",
    "        r2 = float(r2_score(y_test, y_pred))\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        return {\n",
    "            'data_info': data_info,\n",
    "            'model_performance': {\n",
    "                'r2': r2,\n",
    "                'rmse': rmse\n",
    "            },\n",
    "            'model_info': {\n",
    "                'best_config': automl.best_config,\n",
    "                'best_estimator': str(automl.best_estimator)\n",
    "            },\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'error_info': {\n",
    "                'type': type(e).__name__,\n",
    "                'message': str(e),\n",
    "                'data_validation': {\n",
    "                    'X_train_contains_nan': bool(np.isnan(X_train).any()),\n",
    "                    'y_train_contains_nan': bool(np.isnan(y_train).any()),\n",
    "                    'X_train_contains_inf': bool(np.isinf(X_train).any()),\n",
    "                    'y_train_contains_inf': bool(np.isinf(y_train).any())\n",
    "                }\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, target_name):\n",
    "    automl = AutoML()\n",
    "    \n",
    "    settings = {\n",
    "        \"time_budget\": 120,\n",
    "        \"task\": 'regression',\n",
    "        \"metric\": 'mse',\n",
    "        \"estimator_list\": [\n",
    "            'xgboost',       # XGBoost\n",
    "            'rf',            # Random Forest\n",
    "            'extra_tree',    # Extra Trees\n",
    "            #'kneighbor',     # K-Nearest Neighbors\n",
    "            'histgb',        # Histogram-based Gradient Boosting\n",
    "            'enet',          # Elastic Net\n",
    "            #'lassolars',     # Lasso regression with LARS\n",
    "        ],\n",
    "        \"eval_method\": \"holdout\",\n",
    "        \"verbose\": 0,\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42,\n",
    "        \"min_sample_size\": 10,  \n",
    "        \"ensemble\": False,      \n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        X_train = np.array(X_train).astype(np.float32)\n",
    "        X_test = np.array(X_test).astype(np.float32)\n",
    "        y_train = np.array(y_train).astype(np.float32)\n",
    "        y_test = np.array(y_test).astype(np.float32)\n",
    "        \n",
    "        X_train = np.nan_to_num(X_train, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        y_train = np.nan_to_num(y_train, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        y_test = np.nan_to_num(y_test, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        \n",
    "        # Check if we have enough valid samples\n",
    "        if len(X_train) < 10 or len(y_train) < 10:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_info': {\n",
    "                    'type': 'InsufficientData',\n",
    "                    'message': f'Not enough samples: X_train={len(X_train)}, y_train={len(y_train)}'\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Check for constant target values\n",
    "        if np.all(y_train == y_train[0]):\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_info': {\n",
    "                    'type': 'ConstantTarget',\n",
    "                    'message': 'Target values are constant'\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Data information for logging\n",
    "        data_info = {\n",
    "            \"shapes\": {\n",
    "                \"X_train\": X_train.shape,\n",
    "                \"y_train\": y_train.shape,\n",
    "                \"X_test\": X_test.shape,\n",
    "                \"y_test\": y_test.shape\n",
    "            },\n",
    "            \"statistics\": {\n",
    "                \"X_train_range\": [float(X_train.min()), float(X_train.max())],\n",
    "                \"y_train_range\": [float(y_train.min()), float(y_train.max())]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Train model with error catching\n",
    "        try:\n",
    "            automl.fit(X_train, y_train, **settings)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_info': {\n",
    "                    'type': 'FitError',\n",
    "                    'message': str(e)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        y_pred = automl.predict(X_test)\n",
    "        \n",
    "        r2 = float(r2_score(y_test, y_pred))\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        feature_importance = None\n",
    "        if hasattr(automl.model.estimator, 'feature_importances_'):\n",
    "            feature_names = (getattr(X_train, 'columns', None) or \n",
    "                           [f'feature_{i}' for i in range(X_train.shape[1])])\n",
    "            \n",
    "            importance_scores = automl.model.estimator.feature_importances_\n",
    "            feature_importance = {\n",
    "                str(name): float(score)  \n",
    "                for name, score in zip(feature_names, importance_scores)\n",
    "            }\n",
    "            \n",
    "            feature_importance = dict(sorted(\n",
    "                feature_importance.items(), \n",
    "                key=lambda x: x[1], \n",
    "                reverse=True\n",
    "            ))\n",
    "        \n",
    "        return {\n",
    "            'data_info': data_info,\n",
    "            'model_performance': {\n",
    "                'r2': r2,\n",
    "                'rmse': rmse\n",
    "            },\n",
    "            'model_info': {\n",
    "                'best_config': automl.best_config,\n",
    "                'best_estimator': str(automl.best_estimator)\n",
    "            },\n",
    "            'feature_importance': feature_importance,  \n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'error_info': {\n",
    "                'type': type(e).__name__,\n",
    "                'message': str(e),\n",
    "                'data_validation': {\n",
    "                    'X_train_contains_nan': bool(np.isnan(X_train).any()),\n",
    "                    'y_train_contains_nan': bool(np.isnan(y_train).any()),\n",
    "                    'X_train_contains_inf': bool(np.isinf(X_train).any()),\n",
    "                    'y_train_contains_inf': bool(np.isinf(y_train).any())\n",
    "                }\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train function mit feeature names, muss als lister der funktion übergeben werden\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, target_name, feature_names=None):  # Add feature_names parameter\n",
    "    # Initialize FLAML AutoML\n",
    "    automl = AutoML()\n",
    "    \n",
    "    settings = {\n",
    "        \"time_budget\": 120,\n",
    "        \"task\": 'regression',\n",
    "        \"metric\": 'mse',\n",
    "        \"estimator_list\": [\n",
    "            'xgboost',       # XGBoost\n",
    "            'rf',            # Random Forest\n",
    "            'extra_tree',    # Extra Trees\n",
    "            #'kneighbor',     # K-Nearest Neighbors\n",
    "            'histgb',        # Histogram-based Gradient Boosting\n",
    "            'enet',          # Elastic Net\n",
    "            #'lassolars',     # Lasso regression with LARS\n",
    "        ],\n",
    "        \"eval_method\": \"holdout\",\n",
    "        \"verbose\": 0,\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42,\n",
    "        \"min_sample_size\": 10,  \n",
    "        \"ensemble\": False,      \n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        X_train = np.array(X_train).astype(np.float32)\n",
    "        X_test = np.array(X_test).astype(np.float32)\n",
    "        y_train = np.array(y_train).astype(np.float32)\n",
    "        y_test = np.array(y_test).astype(np.float32)\n",
    "        \n",
    "        X_train = np.nan_to_num(X_train, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        y_train = np.nan_to_num(y_train, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        y_test = np.nan_to_num(y_test, nan=0.0, posinf=1e15, neginf=-1e15)\n",
    "        \n",
    "        if len(X_train) < 10 or len(y_train) < 10:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_info': {\n",
    "                    'type': 'InsufficientData',\n",
    "                    'message': f'Not enough samples: X_train={len(X_train)}, y_train={len(y_train)}'\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        if np.all(y_train == y_train[0]):\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_info': {\n",
    "                    'type': 'ConstantTarget',\n",
    "                    'message': 'Target values are constant'\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        data_info = {\n",
    "            \"shapes\": {\n",
    "                \"X_train\": X_train.shape,\n",
    "                \"y_train\": y_train.shape,\n",
    "                \"X_test\": X_test.shape,\n",
    "                \"y_test\": y_test.shape\n",
    "            },\n",
    "            \"statistics\": {\n",
    "                \"X_train_range\": [float(X_train.min()), float(X_train.max())],\n",
    "                \"y_train_range\": [float(y_train.min()), float(y_train.max())]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            automl.fit(X_train, y_train, **settings)\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error_info': {\n",
    "                    'type': 'FitError',\n",
    "                    'message': str(e)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        y_pred = automl.predict(X_test)\n",
    "        \n",
    "        r2 = float(r2_score(y_test, y_pred))\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        feature_importance = None\n",
    "        if hasattr(automl.model.estimator, 'feature_importances_'):\n",
    "            names = feature_names if feature_names is not None else [f'feature_{i}' for i in range(X_train.shape[1])]\n",
    "            \n",
    "            importance_scores = automl.model.estimator.feature_importances_\n",
    "            feature_importance = {\n",
    "                str(name): float(score)\n",
    "                for name, score in zip(names, importance_scores)\n",
    "            }\n",
    "            \n",
    "            feature_importance = dict(sorted(\n",
    "                feature_importance.items(), \n",
    "                key=lambda x: x[1], \n",
    "                reverse=True\n",
    "            ))\n",
    "        \n",
    "        return {\n",
    "            'model_performance': {\n",
    "                'r2': r2,\n",
    "                'rmse': rmse\n",
    "            },\n",
    "            'model_info': {\n",
    "                'best_config': automl.best_config,\n",
    "                'best_estimator': str(automl.best_estimator)\n",
    "            },\n",
    "            'feature_importance': feature_importance,\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'status': 'error',\n",
    "            'error_info': {\n",
    "                'type': type(e).__name__,\n",
    "                'message': str(e)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_ind\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing miners:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for df_type, df in merged_dfs.items():\n",
    "    unique_miners = df['miner'].unique()\n",
    "    print(df_type)    \n",
    "    miner_dataframes = {}\n",
    "\n",
    "    \n",
    "\n",
    "    for miner in unique_miners:\n",
    "        miner_dataframes[miner] = df[df['miner'] == miner]\n",
    "    feature_columns = [\n",
    "        \"Number of Events\",\n",
    "        \"ATS\",\n",
    "        \"Number of Traces\", \n",
    "        \"Distinct Events\",\n",
    "        \"Distinct Traces\",\n",
    "        \"Distinct Start Events\",\n",
    "        \"Distinct End Events\",\n",
    "        \"Average Trace Length\",\n",
    "        \"Max Trace Length\",\n",
    "        \"Min Trace Length\",\n",
    "        \"Event Density\",\n",
    "        \"Absolute Trace Coverage\",\n",
    "        \"Relative Trace Coverage\",\n",
    "        \"Structure\",\n",
    "        \"Level of Detail\",\n",
    "        \"Traces with Self-loops\",\n",
    "        \"Total Self-loops\",\n",
    "        \"Average Self-loop Size\",\n",
    "        \"Event Diversity\",\n",
    "        \"Event Repeatability\",\n",
    "        \"Transition Consistency\",\n",
    "        \"Sequential Complexity\",\n",
    "        \"Rare Sequence Impact\",\n",
    "        \"Event Class Dispersion\",\n",
    "        \"Event Co-occurrence Consistency\",\n",
    "        \"Trace Variability\"\n",
    "    ]\n",
    "    \n",
    "    # Group features by their characteristics\n",
    "    count_features = [\n",
    "        \"Number of Events\",\n",
    "        \"Number of Traces\", \n",
    "        \"Distinct Events\",\n",
    "        \"Distinct Traces\",\n",
    "        \"Distinct Start Events\",\n",
    "        \"Distinct End Events\",\n",
    "        \"Total Self-loops\",\n",
    "    ]\n",
    "\n",
    "    ratio_features = [\n",
    "        \"Event Density\",\n",
    "        \"Relative Trace Coverage\",\n",
    "        \"Structure\",\n",
    "        \"Event Diversity\",\n",
    "        \"Event Repeatability\",\n",
    "        \"Transition Consistency\",\n",
    "        \"Event Co-occurrence Consistency\",\n",
    "    ]\n",
    "\n",
    "    length_features = [\n",
    "        \"ATS\",\n",
    "        \"Average Trace Length\",\n",
    "        \"Max Trace Length\",\n",
    "        \"Min Trace Length\",\n",
    "        \"Level of Detail\",\n",
    "        \"Average Self-loop Size\",\n",
    "    ]\n",
    "\n",
    "    complexity_features = [\n",
    "        \"Sequential Complexity\",\n",
    "        \"Rare Sequence Impact\",\n",
    "        \"Event Class Dispersion\",\n",
    "        \"Trace Variability\",\n",
    "    ]\n",
    "\n",
    "    preprocessed_data = {}\n",
    "\n",
    "    for miner, miner_df in miner_dataframes.items():\n",
    "        features = miner_df[feature_columns]\n",
    "        target_columns = miner_df.select_dtypes(include=['number']).columns.difference(features.columns)\n",
    "        targets = miner_df[target_columns]\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('count_scaler', RobustScaler(), count_features),\n",
    "                ('ratio_scaler', MinMaxScaler(), ratio_features),\n",
    "                ('length_scaler', RobustScaler(), length_features),\n",
    "                ('complexity_scaler', StandardScaler(), complexity_features)\n",
    "            ],\n",
    "            remainder='passthrough'  \n",
    "        )\n",
    "        \n",
    "        preprocessed_data[miner] = {\n",
    "            \"features\": features,\n",
    "            \"targets\": targets,\n",
    "            \"preprocessor\": preprocessor\n",
    "        }\n",
    "\n",
    "    train_test_data = {}\n",
    "    for miner, data in preprocessed_data.items():\n",
    "        features = data['features']\n",
    "        targets = data['targets']\n",
    "        features = features.apply(pd.to_numeric, errors='coerce')\n",
    "        targets = targets.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "        features = features.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        targets = targets.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        epsilon = 1e-10\n",
    "        features = features + epsilon\n",
    "        features = features.clip(-1e15, 1e15)\n",
    "        targets = targets.clip(-1e15, 1e15)\n",
    "        try:\n",
    "            scaled_features = data['preprocessor'].fit_transform(features)\n",
    "            \n",
    "            scaled_features = np.clip(scaled_features, -1e15, 1e15)\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                scaled_features, \n",
    "                targets.values, \n",
    "                test_size=0.15, \n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            train_test_data[miner] = {\n",
    "                \"preprocessor\": data['preprocessor'],\n",
    "                \"X_train\": np.nan_to_num(X_train, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "                \"X_test\": np.nan_to_num(X_test, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "                \"y_train\": np.nan_to_num(y_train, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "                \"y_test\": np.nan_to_num(y_test, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "                \"feature_names\": features.columns\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {miner}: {str(e)}\")\n",
    "            continue\n",
    "    base_output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3'\n",
    "    corr_output_dir = os.path.join(base_output_dir, 'CorrMatrix')\n",
    "    reg_output_dir = os.path.join(base_output_dir, 'RegressionResults')\n",
    "    \n",
    "    for dir_path in [corr_output_dir, reg_output_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    for miner, data in train_test_data.items():\n",
    "        features_df = pd.DataFrame(\n",
    "            data[\"X_train\"],\n",
    "            columns=data[\"feature_names\"]\n",
    "        )\n",
    "        targets_df = pd.DataFrame(\n",
    "            data[\"y_train\"],\n",
    "            columns=preprocessed_data[miner][\"targets\"].columns\n",
    "        )\n",
    "        \n",
    "        corr_matrix = features_df.join(targets_df).corr().loc[features_df.columns, targets_df.columns]\n",
    "        corr_matrix = corr_matrix.fillna(0)\n",
    "        \n",
    "        base_filename = f\"{miner}_{df_type}_mixed_scaling\"\n",
    "        corr_matrix.to_csv(os.path.join(corr_output_dir, f\"{base_filename}_correlation_matrix.csv\"))\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))  # Increased figure size\n",
    "        \n",
    "        sns.heatmap(\n",
    "            corr_matrix,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cmap='coolwarm',\n",
    "            cbar_kws={'label': 'Correlation'},\n",
    "            xticklabels=targets_df.columns,\n",
    "            yticklabels=features_df.columns,\n",
    "            annot_kws={'size': 8},  \n",
    "            center=0,  \n",
    "            vmin=-1,   \n",
    "            vmax=1     \n",
    "        )\n",
    "        \n",
    "        plt.title(f\"Feature-Target Correlation Matrix for {miner}\\n({df_type}, mixed scaling)\", \n",
    "                pad=20,  \n",
    "                size=14, \n",
    "                weight='bold')\n",
    "        plt.ylabel(\"Features\", size=12, weight='bold')\n",
    "        plt.xlabel(\"Targets\", size=12, weight='bold')\n",
    "        \n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(\n",
    "            os.path.join(corr_output_dir, f\"{base_filename}_correlation_matrix.png\"),\n",
    "            dpi=300,\n",
    "            bbox_inches='tight'\n",
    "        )\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "    all_results = {\n",
    "        \"df_type\": df_type,\n",
    "        \"miners\": {}\n",
    "    }\n",
    "    # For each miner\n",
    "    for miner, data in tqdm(train_test_data.items(), desc=\"Processing miners\"):\n",
    "        miner_results = {}\n",
    "        target_names = preprocessed_data[miner]['targets'].columns\n",
    "        \n",
    "        # For each target metric\n",
    "        for i, target_name in enumerate(target_names):\n",
    "            try:\n",
    "                y_train = data['y_train'][:, i]\n",
    "                y_test = data['y_test'][:, i]\n",
    "                \n",
    "                results = train_and_evaluate_models(\n",
    "                    data['X_train'], \n",
    "                    data['X_test'], \n",
    "                    y_train, \n",
    "                    y_test, \n",
    "                    target_name\n",
    "                )\n",
    "                \n",
    "                miner_results[target_name] = results\n",
    "                    \n",
    "            except Exception as e:\n",
    "                miner_results[target_name] = {\n",
    "                    'status': 'error',\n",
    "                    'error_message': str(e)\n",
    "                }\n",
    "        \n",
    "        all_results[\"miners\"][miner] = miner_results\n",
    "        miner_filename = os.path.join(\n",
    "            reg_output_dir, \n",
    "            f'regression_results_{miner.replace(\" \", \"_\")}_{df_type}_mixed_scaling.json'\n",
    "        )\n",
    "        with open(miner_filename, 'w') as f:\n",
    "            json.dump({\n",
    "                \"df_type\": df_type,\n",
    "                \"scaling_info\": {\n",
    "                    \"count_features\": count_features,\n",
    "                    \"ratio_features\": ratio_features,\n",
    "                    \"length_features\": length_features,\n",
    "                    \"complexity_features\": complexity_features\n",
    "                },\n",
    "                \"miner_results\": miner_results\n",
    "            }, f, indent=4)\n",
    "\n",
    "    # Save combined results\n",
    "    combined_filename = os.path.join(reg_output_dir, f'regression_results_all_{df_type}.json')\n",
    "    with open(combined_filename, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_type, df in merged_dfs.items():\n",
    "    unique_miners = df['miner'].unique()\n",
    "    print(df_type)   \n",
    "    miner_dataframes = {}\n",
    "    \n",
    "\n",
    "    for miner in unique_miners:\n",
    "        miner_dataframes[miner] = df[df['miner'] == miner]\n",
    "\n",
    "    feature_columns = [\n",
    "        \"Number of Events\",\n",
    "        \"ATS\",\n",
    "        \"Number of Traces\", \n",
    "        \"Distinct Events\",\n",
    "        \"Distinct Traces\",\n",
    "        \"Distinct Start Events\",\n",
    "        \"Distinct End Events\",\n",
    "        \"Average Trace Length\",\n",
    "        \"Max Trace Length\",\n",
    "        \"Min Trace Length\",\n",
    "        \"Event Density\",\n",
    "        \"Absolute Trace Coverage\",\n",
    "        \"Relative Trace Coverage\",\n",
    "        \"Structure\",\n",
    "        \"Level of Detail\",\n",
    "        \"Traces with Self-loops\",\n",
    "        \"Total Self-loops\",\n",
    "        \"Average Self-loop Size\",\n",
    "        \"Event Diversity\",\n",
    "        \"Event Repeatability\",\n",
    "        \"Transition Consistency\",\n",
    "        \"Sequential Complexity\",\n",
    "        \"Rare Sequence Impact\",\n",
    "        \"Event Class Dispersion\",\n",
    "        \"Event Co-occurrence Consistency\",\n",
    "        \"Trace Variability\"\n",
    "    ]\n",
    "    preprocessed_data = {}\n",
    "\n",
    "\n",
    "    for miner, miner_df in miner_dataframes.items():\n",
    "        features = miner_df[feature_columns]\n",
    "        \n",
    "        target_columns = miner_df.select_dtypes(include=['number']).columns.difference(features.columns)\n",
    "        targets = miner_df[target_columns]\n",
    "        \n",
    "        preprocessed_data[miner] = {\n",
    "            \"features\": features,\n",
    "            \"targets\": targets\n",
    "        }\n",
    "\n",
    "\n",
    " \n",
    "    train_test_data = {}\n",
    "\n",
    "    # Process each miner's data\n",
    "    for miner, data in preprocessed_data.items():\n",
    "        # Extract features and targets\n",
    "        features = data['features']\n",
    "        targets = data['targets']\n",
    "        \n",
    "        # Ensure no missing values in features or targets\n",
    "        features = features.fillna(0)\n",
    "        targets = targets.fillna(0)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            scaled_features, \n",
    "            targets.values, \n",
    "            test_size=0.15, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        train_test_data[miner] = {\n",
    "            \"scaler\": scaler,\n",
    "            \"X_train\": X_train,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_test\": y_test\n",
    "        }\n",
    "\n",
    "  \n",
    "    output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3/CorrMatrix'\n",
    "    os.makedirs(output_dir, exist_ok=True)  \n",
    "\n",
    "    for miner, splits in train_test_data.items():\n",
    "        features_df = pd.DataFrame(splits[\"X_train\"], columns=preprocessed_data[miner][\"features\"].columns)\n",
    "        targets_df = pd.DataFrame(splits[\"y_train\"], columns=preprocessed_data[miner][\"targets\"].columns)\n",
    "        \n",
    "        corr_matrix = features_df.join(targets_df).corr().loc[features_df.columns, targets_df.columns]\n",
    "\n",
    "        corr_matrix = corr_matrix.fillna(0)\n",
    "        \n",
    "        csv_file_name = os.path.join(output_dir, f\"{miner}_{df_type}_correlation_matrix.csv\")\n",
    "        corr_matrix.to_csv(csv_file_name)\n",
    "        \n",
    "        png_file_name = os.path.join(output_dir, f\"{miner}_{df_type}_correlation_matrix.png\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(\n",
    "            corr_matrix,\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            cmap='coolwarm',\n",
    "            cbar_kws={'label': 'Correlation'},\n",
    "            xticklabels=targets_df.columns,\n",
    "            yticklabels=features_df.columns\n",
    "        )\n",
    "        plt.title(f\"Feature-Target Correlation Matrix for {miner} ({df_type})\")\n",
    "        plt.ylabel(\"Features\")\n",
    "        plt.xlabel(\"Targets\")\n",
    "        plt.savefig(png_file_name)\n",
    "        plt.close()\n",
    "\n",
    "    output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3/RegressionResults_1s_test'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    all_results = {\n",
    "        \"df_type\": df_type,  \n",
    "        \"miners\": {}        \n",
    "    }\n",
    "\n",
    "    # For each miner\n",
    "    for miner, data in tqdm(train_test_data.items(), desc=\"Processing miners\"):\n",
    "        miner_results = {}\n",
    "        target_names = preprocessed_data[miner]['targets'].columns\n",
    "        \n",
    "        # For each target metric\n",
    "        for i, target_name in enumerate(target_names):\n",
    "            try:\n",
    "                # Extract the specific target column\n",
    "                y_train = data['y_train'][:, i]\n",
    "                y_test = data['y_test'][:, i]\n",
    "                \n",
    "                results = train_and_evaluate_models(\n",
    "                    data['X_train'], \n",
    "                    data['X_test'], \n",
    "                    y_train, \n",
    "                    y_test, \n",
    "                    target_name\n",
    "                )\n",
    "                \n",
    "                miner_results[target_name] = results\n",
    "                    \n",
    "            except Exception as e:\n",
    "                miner_results[target_name] = {\n",
    "                    'status': 'error',\n",
    "                    'error_message': str(e)\n",
    "                }\n",
    "        \n",
    "        all_results[\"miners\"][miner] = miner_results \n",
    "        \n",
    "        miner_filename = os.path.join(output_dir, f'regression_results_{miner.replace(\" \", \"_\")}_{df_type}.json')\n",
    "        with open(miner_filename, 'w') as f:\n",
    "            json.dump({\n",
    "                \"df_type\": df_type,\n",
    "                \"miner_results\": miner_results\n",
    "            }, f, indent=4)\n",
    "\n",
    "    combined_filename = os.path.join(output_dir, f'regression_results_all_{df_type}.json')\n",
    "    with open(combined_filename, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation / Regresssion Analysis (großer DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_df = pd.concat([\n",
    "    df.assign(preprocessing_type=preproc_type) \n",
    "    for preproc_type, df in merged_dfs.items()\n",
    "], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_logtypes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing miners: 100%|██████████| 5/5 [00:07<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "df = all_merged_df\n",
    "df_name = df['file'].iloc[0]\n",
    "df_type = 'all_logtypes'\n",
    "unique_miners = df['miner'].unique()\n",
    "print(df_type)   \n",
    "miner_dataframes = {}\n",
    "\n",
    "for miner in unique_miners:\n",
    "    miner_dataframes[miner] = df[df['miner'] == miner]\n",
    "\n",
    "feature_columns = [\n",
    "    \"Number of Events\",\n",
    "    \"ATS\",\n",
    "    \"Number of Traces\", \n",
    "    \"Distinct Events\",\n",
    "    \"Distinct Traces\",\n",
    "    \"Distinct Start Events\",\n",
    "    \"Distinct End Events\",\n",
    "    \"Average Trace Length\",\n",
    "    \"Max Trace Length\",\n",
    "    \"Min Trace Length\",\n",
    "    \"Event Density\",\n",
    "    \"Absolute Trace Coverage\",\n",
    "    \"Relative Trace Coverage\",\n",
    "    \"Structure\",\n",
    "    \"Level of Detail\",\n",
    "    \"Traces with Self-loops\",\n",
    "    \"Total Self-loops\",\n",
    "    \"Average Self-loop Size\",\n",
    "    \"Event Diversity\",\n",
    "    \"Event Repeatability\",\n",
    "    \"Transition Consistency\",\n",
    "    \"Sequential Complexity\",\n",
    "    \"Rare Sequence Impact\",\n",
    "    \"Event Class Dispersion\",\n",
    "    \"Event Co-occurrence Consistency\",\n",
    "    \"Trace Variability\"\n",
    "]\n",
    "\n",
    "count_features = [\n",
    "    \"Number of Events\",\n",
    "    \"Number of Traces\", \n",
    "    \"Distinct Events\",\n",
    "    \"Distinct Traces\",\n",
    "    \"Distinct Start Events\",\n",
    "    \"Distinct End Events\",\n",
    "    \"Total Self-loops\",\n",
    "]\n",
    "\n",
    "ratio_features = [\n",
    "    \"Event Density\",\n",
    "    \"Relative Trace Coverage\",\n",
    "    \"Structure\",\n",
    "    \"Event Diversity\",\n",
    "    \"Event Repeatability\",\n",
    "    \"Transition Consistency\",\n",
    "    \"Event Co-occurrence Consistency\",\n",
    "]\n",
    "\n",
    "length_features = [\n",
    "    \"ATS\",\n",
    "    \"Average Trace Length\",\n",
    "    \"Max Trace Length\",\n",
    "    \"Min Trace Length\",\n",
    "    \"Level of Detail\",\n",
    "    \"Average Self-loop Size\",\n",
    "]\n",
    "\n",
    "complexity_features = [\n",
    "    \"Sequential Complexity\",\n",
    "    \"Rare Sequence Impact\",\n",
    "    \"Event Class Dispersion\",\n",
    "    \"Trace Variability\",\n",
    "]\n",
    "\n",
    "preprocessed_data = {}\n",
    "\n",
    "for miner, miner_df in miner_dataframes.items():\n",
    "    features = miner_df[feature_columns]\n",
    "    \n",
    "    target_columns = miner_df.select_dtypes(include=['number']).columns.difference(features.columns)\n",
    "    targets = miner_df[target_columns]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('count_scaler', RobustScaler(), count_features),\n",
    "            ('ratio_scaler', MinMaxScaler(), ratio_features),\n",
    "            ('length_scaler', RobustScaler(), length_features),\n",
    "            ('complexity_scaler', StandardScaler(), complexity_features)\n",
    "        ],\n",
    "        remainder='passthrough'  \n",
    "    )\n",
    "    \n",
    "    preprocessed_data[miner] = {\n",
    "        \"features\": features,\n",
    "        \"targets\": targets,\n",
    "        \"preprocessor\": preprocessor\n",
    "    }\n",
    "\n",
    "train_test_data = {}\n",
    "\n",
    "for miner, data in preprocessed_data.items():\n",
    "    features = data['features']\n",
    "    targets = data['targets']\n",
    "    features = features.apply(pd.to_numeric, errors='coerce')\n",
    "    targets = targets.apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    features = features.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    targets = targets.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    epsilon = 1e-10\n",
    "    features = features + epsilon\n",
    "    \n",
    "    features = features.clip(-1e15, 1e15)\n",
    "    targets = targets.clip(-1e15, 1e15)\n",
    "    \n",
    "    try:\n",
    "        scaled_features = data['preprocessor'].fit_transform(features)\n",
    "        \n",
    "        scaled_features = np.clip(scaled_features, -1e15, 1e15)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            scaled_features, \n",
    "            targets.values, \n",
    "            test_size=0.15, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        train_test_data[miner] = {\n",
    "            \"preprocessor\": data['preprocessor'],\n",
    "            \"X_train\": np.nan_to_num(X_train, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "            \"X_test\": np.nan_to_num(X_test, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "            \"y_train\": np.nan_to_num(y_train, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "            \"y_test\": np.nan_to_num(y_test, nan=0.0, posinf=1e15, neginf=-1e15),\n",
    "            \"feature_names\": features.columns\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {miner}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "base_output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3'\n",
    "corr_output_dir = os.path.join(base_output_dir, 'CorrMatrix_Miner')\n",
    "reg_output_dir = os.path.join(base_output_dir, 'RegressionResults_Miner')\n",
    "\n",
    "for dir_path in [corr_output_dir, reg_output_dir]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "for miner, miner_df in miner_dataframes.items():\n",
    "    features_df = miner_df[feature_columns]\n",
    "    \n",
    "    target_columns = miner_df.select_dtypes(include=['number']).columns.difference(features_df.columns)\n",
    "    targets_df = miner_df[target_columns]\n",
    "    \n",
    "    corr_matrix = features_df.join(targets_df).corr().loc[features_df.columns, targets_df.columns]\n",
    "    corr_matrix = corr_matrix.fillna(0)\n",
    "    \n",
    "    base_filename = f\"{miner}_{df_type}_original_values\"\n",
    "    corr_matrix.to_csv(os.path.join(corr_output_dir, f\"{base_filename}_correlation_matrix.csv\"))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10)) \n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap='coolwarm',\n",
    "        cbar_kws={'label': 'Correlation'},\n",
    "        xticklabels=targets_df.columns,\n",
    "        yticklabels=features_df.columns,\n",
    "        annot_kws={'size': 8},  \n",
    "        center=0,  \n",
    "        vmin=-1,   \n",
    "        vmax=1     \n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Feature-Target Correlation Matrix for {miner}\\n({df_type}, original values)\", \n",
    "            pad=20,  \n",
    "            size=14, \n",
    "            weight='bold')\n",
    "    plt.ylabel(\"Features\", size=12, weight='bold')\n",
    "    plt.xlabel(\"Targets\", size=12, weight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(\n",
    "        os.path.join(corr_output_dir, f\"{base_filename}_correlation_matrix.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "all_results = {\n",
    "    \"df_type\": df_type,\n",
    "    \"miners\": {}\n",
    "}\n",
    "\n",
    "for miner, data in tqdm(train_test_data.items(), desc=\"Processing miners\"):\n",
    "    miner_results = {}\n",
    "    target_names = preprocessed_data[miner]['targets'].columns\n",
    "    \n",
    "    for i, target_name in enumerate(target_names):\n",
    "        try:\n",
    "            y_train = data['y_train'][:, i]\n",
    "            y_test = data['y_test'][:, i]\n",
    "            \n",
    "            results = train_and_evaluate_models(\n",
    "                data['X_train'], \n",
    "                data['X_test'], \n",
    "                y_train, \n",
    "                y_test, \n",
    "                target_name\n",
    "            )\n",
    "            \n",
    "            miner_results[target_name] = results\n",
    "                \n",
    "        except Exception as e:\n",
    "            miner_results[target_name] = {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    all_results[\"miners\"][miner] = miner_results\n",
    "    \n",
    "    miner_filename = os.path.join(\n",
    "        reg_output_dir, \n",
    "        f'regression_results_{miner.replace(\" \", \"_\")}_{df_type}_mixed_scaling.json'\n",
    "    )\n",
    "    with open(miner_filename, 'w') as f:\n",
    "        json.dump({\n",
    "            \"df_type\": df_type,\n",
    "            \"scaling_info\": {\n",
    "                \"count_features\": count_features,\n",
    "                \"ratio_features\": ratio_features,\n",
    "                \"length_features\": length_features,\n",
    "                \"complexity_features\": complexity_features\n",
    "            },\n",
    "            \"miner_results\": miner_results\n",
    "        }, f, indent=4)\n",
    "\n",
    "combined_filename = os.path.join(reg_output_dir, f'regression_results_all_{df_type}.json')\n",
    "with open(combined_filename, 'w') as f:\n",
    "    json.dump(all_results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation/Regression BIIIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_merged_df\n",
    "df_name = df['file'].iloc[0]\n",
    "df_type = 'all_logtypes'\n",
    "\n",
    "\n",
    "feature_columns = [\n",
    "    \"Number of Events\",\n",
    "    \"ATS\",\n",
    "    \"Number of Traces\", \n",
    "    \"Distinct Events\",\n",
    "    \"Distinct Traces\",\n",
    "    \"Distinct Start Events\",\n",
    "    \"Distinct End Events\",\n",
    "    \"Average Trace Length\",\n",
    "    \"Max Trace Length\",\n",
    "    \"Min Trace Length\",\n",
    "    \"Event Density\",\n",
    "    \"Absolute Trace Coverage\",\n",
    "    \"Relative Trace Coverage\",\n",
    "    \"Structure\",\n",
    "    \"Level of Detail\",\n",
    "    \"Traces with Self-loops\",\n",
    "    \"Total Self-loops\",\n",
    "    \"Average Self-loop Size\",\n",
    "    \"Event Diversity\",\n",
    "    \"Event Repeatability\",\n",
    "    \"Transition Consistency\",\n",
    "    \"Sequential Complexity\",\n",
    "    \"Rare Sequence Impact\",\n",
    "    \"Event Class Dispersion\",\n",
    "    \"Event Co-occurrence Consistency\",\n",
    "    \"Trace Variability\"\n",
    "]\n",
    "\n",
    "count_features = [\n",
    "    \"Number of Events\",\n",
    "    \"Number of Traces\", \n",
    "    \"Distinct Events\",\n",
    "    \"Distinct Traces\",\n",
    "    \"Distinct Start Events\",\n",
    "    \"Distinct End Events\",\n",
    "    \"Total Self-loops\",\n",
    "]\n",
    "\n",
    "ratio_features = [\n",
    "    \"Event Density\",\n",
    "    \"Relative Trace Coverage\",\n",
    "    \"Structure\",\n",
    "    \"Event Diversity\",\n",
    "    \"Event Repeatability\",\n",
    "    \"Transition Consistency\",\n",
    "    \"Event Co-occurrence Consistency\",\n",
    "]\n",
    "\n",
    "length_features = [\n",
    "    \"ATS\",\n",
    "    \"Average Trace Length\",\n",
    "    \"Max Trace Length\",\n",
    "    \"Min Trace Length\",\n",
    "    \"Level of Detail\",\n",
    "    \"Average Self-loop Size\",\n",
    "]\n",
    "\n",
    "complexity_features = [\n",
    "    \"Sequential Complexity\",\n",
    "    \"Rare Sequence Impact\",\n",
    "    \"Event Class Dispersion\",\n",
    "    \"Trace Variability\",\n",
    "]\n",
    "\n",
    "\n",
    "features = df[feature_columns]\n",
    "target_columns = df.select_dtypes(include=['number']).columns.difference(features.columns)\n",
    "targets = df[target_columns]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('count_scaler', RobustScaler(), count_features),\n",
    "        ('ratio_scaler', MinMaxScaler(), ratio_features),\n",
    "        ('length_scaler', RobustScaler(), length_features),\n",
    "        ('complexity_scaler', StandardScaler(), complexity_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "try:\n",
    "    features = features.apply(pd.to_numeric, errors='coerce')\n",
    "    targets = targets.apply(pd.to_numeric, errors='coerce')\n",
    "    features = features.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    targets = targets.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    \n",
    "    features = features + 1e-10\n",
    "    features = features.clip(-1e15, 1e15)\n",
    "    targets = targets.clip(-1e15, 1e15)\n",
    "    \n",
    "    scaled_features = preprocessor.fit_transform(features)\n",
    "    scaled_features = np.clip(scaled_features, -1e15, 1e15)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        scaled_features,\n",
    "        targets.values,\n",
    "        test_size=0.15,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    base_output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3'\n",
    "    corr_output_dir = os.path.join(base_output_dir, 'CorrMatrix_Combined')\n",
    "    reg_output_dir = os.path.join(base_output_dir, 'RegressionResults_Combined')\n",
    "    \n",
    "    for dir_path in [corr_output_dir, reg_output_dir]:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    corr_matrix = features.join(targets).corr().loc[features.columns, targets.columns]\n",
    "    corr_matrix = corr_matrix.fillna(0)\n",
    "    \n",
    "    base_filename = f\"combined_{df_type}_original_values\"\n",
    "    corr_matrix.to_csv(os.path.join(corr_output_dir, f\"{base_filename}_correlation_matrix.csv\"))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap='coolwarm',\n",
    "        cbar_kws={'label': 'Correlation'},\n",
    "        xticklabels=targets.columns,\n",
    "        yticklabels=features.columns,\n",
    "        annot_kws={'size': 8},\n",
    "        center=0,\n",
    "        vmin=-1,\n",
    "        vmax=1\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Feature-Target Correlation Matrix\\n({df_type}, original values)\", \n",
    "            pad=20,\n",
    "            size=14,\n",
    "            weight='bold')\n",
    "    plt.ylabel(\"Features\", size=12, weight='bold')\n",
    "    plt.xlabel(\"Targets\", size=12, weight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(\n",
    "        os.path.join(corr_output_dir, f\"{base_filename}_correlation_matrix.png\"),\n",
    "        dpi=300,\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close()\n",
    "    \n",
    "    all_results = {\n",
    "        \"df_type\": df_type,\n",
    "        \"results\": {}\n",
    "    }\n",
    "    \n",
    "    for i, target_name in enumerate(targets.columns):\n",
    "        try:\n",
    "            results = train_and_evaluate_models(\n",
    "                X_train,\n",
    "                X_test,\n",
    "                y_train[:, i],\n",
    "                y_test[:, i],\n",
    "                target_name\n",
    "            )\n",
    "            all_results[\"results\"][target_name] = results\n",
    "        except Exception as e:\n",
    "            all_results[\"results\"][target_name] = {\n",
    "                'status': 'error',\n",
    "                'error_message': str(e)\n",
    "            }\n",
    "    \n",
    "    results_filename = os.path.join(reg_output_dir, f'regression_results_{df_type}_mixed_scaling.json')\n",
    "    with open(results_filename, 'w') as f:\n",
    "        json.dump({\n",
    "            \"df_type\": df_type,\n",
    "            \"scaling_info\": {\n",
    "                \"count_features\": count_features,\n",
    "                \"ratio_features\": ratio_features,\n",
    "                \"length_features\": length_features,\n",
    "                \"complexity_features\": complexity_features\n",
    "            },\n",
    "            \"results\": all_results\n",
    "        }, f, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing data: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Analysis (predict best Algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    \"Number of Events\",\n",
    "    \"ATS\",\n",
    "    \"Number of Traces\", \n",
    "    \"Distinct Events\",\n",
    "    \"Distinct Traces\",\n",
    "    \"Distinct Start Events\",\n",
    "    \"Distinct End Events\",\n",
    "    \"Average Trace Length\",\n",
    "    \"Max Trace Length\",\n",
    "    \"Min Trace Length\",\n",
    "    \"Event Density\",\n",
    "    \"Absolute Trace Coverage\",\n",
    "    \"Relative Trace Coverage\",\n",
    "    \"Structure\",\n",
    "    \"Level of Detail\",\n",
    "    \"Traces with Self-loops\",\n",
    "    \"Total Self-loops\",\n",
    "    \"Average Self-loop Size\",\n",
    "    \"Event Diversity\",\n",
    "    \"Event Repeatability\",\n",
    "    \"Transition Consistency\",\n",
    "    \"Sequential Complexity\",\n",
    "    \"Rare Sequence Impact\",\n",
    "    \"Event Class Dispersion\",\n",
    "    \"Event Co-occurrence Consistency\",\n",
    "    \"Trace Variability\"\n",
    "]\n",
    "\n",
    "def keep_best_miner_per_file(df, column_name):\n",
    "    \"\"\"\n",
    "    Filter DataFrame to keep only rows where the miner has the highest value\n",
    "    for the specified column per file and remove other metric columns.\n",
    "    Excludes ILP Miner for specific fitness-related metrics.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    ilp_exclude_metrics = [\n",
    "        #'perc_fit_traces',\n",
    "        #'average_trace_fitness',\n",
    "        'log_fitness',\n",
    "        #'percentage_of_fitting_traces'\n",
    "    ]\n",
    "    \n",
    "    if column_name in ilp_exclude_metrics:\n",
    "        df_copy = df_copy[df_copy['miner'] != 'ILP Miner']\n",
    "    \n",
    "    metric_columns = [\n",
    "        #'perc_fit_traces',\n",
    "        #'average_trace_fitness',\n",
    "        'log_fitness',\n",
    "        #'percentage_of_fitting_traces',\n",
    "        'precision',\n",
    "        'generalization',\n",
    "        'simplicity',\n",
    "        'metricsAverageWeight',\n",
    "        'fscore',\n",
    "        #'score'\n",
    "    ]\n",
    "    \n",
    "    idx = df_copy.groupby('file')[column_name].idxmax()\n",
    "    \n",
    "    best_miners_df = df_copy.loc[idx]\n",
    "    \n",
    "    columns_to_remove = [col for col in metric_columns if col != column_name]\n",
    "    best_miners_df = best_miners_df.drop(columns=columns_to_remove)\n",
    "    \n",
    "    best_miners_df = best_miners_df.reset_index(drop=True)\n",
    "    \n",
    "    return best_miners_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Entfernen!!!!\n",
    "\n",
    "metrics = [\n",
    "    #'perc_fit_traces',\n",
    "    #'average_trace_fitness',\n",
    "    'log_fitness',\n",
    "    #'percentage_of_fitting_traces',\n",
    "    'precision',\n",
    "    'generalization',\n",
    "    'simplicity',\n",
    "    'metricsAverageWeight',\n",
    "    'fscore',\n",
    "]\n",
    "\n",
    "all_preprocessing_results = {}\n",
    "\n",
    "for preproc_type, df in merged_dfs.items():\n",
    "    \n",
    "    \n",
    "    all_metric_results = {}\n",
    "    \n",
    "    for metric in metrics:\n",
    "        \n",
    "        \n",
    "        best_miners_df = keep_best_miner_per_file(df, metric)\n",
    "\n",
    "        X = best_miners_df[feature_columns]\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(best_miners_df['miner'])\n",
    "        \n",
    "        miner_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "        \n",
    "        \n",
    "        count_features = [\n",
    "            \"Number of Events\",\n",
    "            \"Number of Traces\", \n",
    "            \"Distinct Events\",\n",
    "            \"Distinct Traces\",\n",
    "            \"Distinct Start Events\",\n",
    "            \"Distinct End Events\",\n",
    "            \"Total Self-loops\",\n",
    "        ]\n",
    "\n",
    "        ratio_features = [\n",
    "            \"Event Density\",\n",
    "            \"Relative Trace Coverage\",\n",
    "            \"Structure\",\n",
    "            \"Event Diversity\",\n",
    "            \"Event Repeatability\",\n",
    "            \"Transition Consistency\",\n",
    "            \"Event Co-occurrence Consistency\",\n",
    "        ]\n",
    "\n",
    "        length_features = [\n",
    "            \"ATS\",\n",
    "            \"Average Trace Length\",\n",
    "            \"Max Trace Length\",\n",
    "            \"Min Trace Length\",\n",
    "            \"Level of Detail\",\n",
    "            \"Average Self-loop Size\",\n",
    "        ]\n",
    "\n",
    "        complexity_features = [\n",
    "            \"Sequential Complexity\",\n",
    "            \"Rare Sequence Impact\",\n",
    "            \"Event Class Dispersion\",\n",
    "            \"Trace Variability\",\n",
    "        ]\n",
    "        \n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('count_scaler', RobustScaler(), count_features),\n",
    "                ('ratio_scaler', MinMaxScaler(), ratio_features),\n",
    "                ('length_scaler', RobustScaler(), length_features),\n",
    "                ('complexity_scaler', StandardScaler(), complexity_features)\n",
    "            ],\n",
    "            remainder='passthrough' \n",
    "        )\n",
    "        \n",
    "        X = X.fillna(0)\n",
    "        X_scaled = preprocessor.fit_transform(X)\n",
    "        \n",
    "        total_samples = len(X)\n",
    "        test_size = 0.2 if total_samples < 100 else 0.15\n",
    "        \n",
    "        try:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, \n",
    "                y,\n",
    "                test_size=test_size, \n",
    "                random_state=42,\n",
    "                stratify=y\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"Error in train_test_split: {e}\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X_scaled, \n",
    "                y,\n",
    "                test_size=test_size, \n",
    "                random_state=42\n",
    "            )\n",
    "        \n",
    "        \n",
    "        unique, counts = np.unique(y_train, return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            miner_name = label_encoder.inverse_transform([u])[0]\n",
    "            print(f\"{miner_name}: {c} samples\")\n",
    "        \n",
    "        results = train_and_evaluate_models(\n",
    "            X_train,\n",
    "            X_test,\n",
    "            y_train,\n",
    "            y_test,\n",
    "            f'miner_prediction_{metric}'\n",
    "        )\n",
    "        \n",
    "        all_metric_results[metric] = {\n",
    "            'results': results,\n",
    "            'miner_mapping': miner_mapping,\n",
    "            'class_distribution': dict(zip(label_encoder.inverse_transform(unique), counts))\n",
    "        }\n",
    "        \n",
    "    \n",
    "    all_preprocessing_results[preproc_type] = all_metric_results\n",
    "\n",
    "output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3/Regression_pred_best_miner'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'miner_prediction_results_all_preprocessing.json')\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "serializable_results = {\n",
    "    preproc_type: {\n",
    "        metric: {\n",
    "            key: {\n",
    "                k: convert_to_serializable(v) if isinstance(v, (np.integer, np.floating, np.ndarray)) else v\n",
    "                for k, v in value.items()\n",
    "            }\n",
    "            for key, value in results.items()\n",
    "        }\n",
    "        for metric, results in metric_results.items()\n",
    "    }\n",
    "    for preproc_type, metric_results in all_preprocessing_results.items()\n",
    "}\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "print(f\"\\nResults saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best miner prediction unabhängig von preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    #'perc_fit_traces',\n",
    "    #'average_trace_fitness',\n",
    "    'log_fitness',\n",
    "    #'percentage_of_fitting_traces',\n",
    "    'precision',\n",
    "    'generalization',\n",
    "    'simplicity',\n",
    "    'metricsAverageWeight',\n",
    "    'fscore',\n",
    "]\n",
    "\n",
    "all_metric_results = {}\n",
    "\n",
    "df = pd.concat(merged_dfs.values(), ignore_index=True)\n",
    "\n",
    "for metric in metrics:\n",
    "    best_miners_df = keep_best_miner_per_file(df, metric)\n",
    "    \n",
    "    X = best_miners_df[feature_columns]\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(best_miners_df['miner'])\n",
    "    \n",
    "    miner_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    \n",
    "    # Group features by their characteristics\n",
    "    count_features = [\n",
    "        \"Number of Events\",\n",
    "        \"Number of Traces\", \n",
    "        \"Distinct Events\",\n",
    "        \"Distinct Traces\",\n",
    "        \"Distinct Start Events\",\n",
    "        \"Distinct End Events\",\n",
    "        \"Total Self-loops\",\n",
    "    ]\n",
    "\n",
    "    ratio_features = [\n",
    "        \"Event Density\",\n",
    "        \"Relative Trace Coverage\",\n",
    "        \"Structure\",\n",
    "        \"Event Diversity\",\n",
    "        \"Event Repeatability\",\n",
    "        \"Transition Consistency\",\n",
    "        \"Event Co-occurrence Consistency\",\n",
    "    ]\n",
    "\n",
    "    length_features = [\n",
    "        \"ATS\",\n",
    "        \"Average Trace Length\",\n",
    "        \"Max Trace Length\",\n",
    "        \"Min Trace Length\",\n",
    "        \"Level of Detail\",\n",
    "        \"Average Self-loop Size\",\n",
    "    ]\n",
    "\n",
    "    complexity_features = [\n",
    "        \"Sequential Complexity\",\n",
    "        \"Rare Sequence Impact\",\n",
    "        \"Event Class Dispersion\",\n",
    "        \"Trace Variability\",\n",
    "    ]\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('count_scaler', RobustScaler(), count_features),\n",
    "            ('ratio_scaler', MinMaxScaler(), ratio_features),\n",
    "            ('length_scaler', RobustScaler(), length_features),\n",
    "            ('complexity_scaler', StandardScaler(), complexity_features)\n",
    "        ],\n",
    "        remainder='passthrough' \n",
    "    )\n",
    "    \n",
    "    X = X.fillna(0)\n",
    "    X_scaled = preprocessor.fit_transform(X)\n",
    "    \n",
    "    total_samples = len(X)\n",
    "    test_size = 0.2 if total_samples < 100 else 0.15\n",
    "    \n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, \n",
    "            y,\n",
    "            test_size=test_size, \n",
    "            random_state=42,\n",
    "            stratify=y\n",
    "        )\n",
    "    except ValueError as e:\n",
    "        print(f\"Error in train_test_split: {e}\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_scaled, \n",
    "            y,\n",
    "            test_size=test_size, \n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    for u, c in zip(unique, counts):\n",
    "        miner_name = label_encoder.inverse_transform([u])[0]\n",
    "        print(f\"{miner_name}: {c} samples\")\n",
    "    \n",
    "    results = train_and_evaluate_models(\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        f'miner_prediction_{metric}'\n",
    "    )\n",
    "    \n",
    "    all_metric_results[metric] = {\n",
    "        'results': results,\n",
    "        'miner_mapping': miner_mapping,\n",
    "        'class_distribution': dict(zip(label_encoder.inverse_transform(unique), counts))\n",
    "    }\n",
    "\n",
    "output_dir = '/home/jupyter-benjamin.andrick-3cf07/test/Outputs3/Regression_pred_best_miner_combined'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, 'miner_prediction_results.json')\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "serializable_results = {\n",
    "    metric: {\n",
    "        key: {\n",
    "            k: convert_to_serializable(v) if isinstance(v, (np.integer, np.floating, np.ndarray)) else v\n",
    "            for k, v in value.items()\n",
    "        }\n",
    "        for key, value in results.items()\n",
    "    }\n",
    "    for metric, results in all_metric_results.items()\n",
    "}\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(serializable_results, f, indent=4)\n",
    "\n",
    "print(f\"\\nResults saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
